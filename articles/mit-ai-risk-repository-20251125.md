# The MIT AI Risk Repository: A Comprehensive Meta-Review, Database, and Taxonomy of Risks From Artificial Intelligence
**Authors:** Peter Slattery, Alexander K. Saeri, Emily A. C. Grundy, Jess Graham, Michael Noetel, Risto Uuk, James Dao, Soroush Pour, Stephen Casper, Neil Thompson

**Published:** 14 August 2024

---

## Key Points
- The repository contains 777 AI risks extracted from 43 taxonomies, providing a comprehensive database for researchers, policymakers, and industry professionals.
- A Causal Taxonomy classifies risks by entity (human/AI), intentionality (intentional/unintentional), and timing (pre-deployment/post-deployment).
- A Domain Taxonomy organises risks into seven domains and 23 subdomains, including discrimination, privacy, misinformation, malicious actors, human-computer interaction, socioeconomic impacts, and system safety.
- The database reveals significant fragmentation in risk literature, with some risks like privacy (70%+ coverage) widely discussed whilst others like AI welfare (<1%) remain underexplored.
- The repository is publicly accessible as a living database that will be continuously updated to ensure relevancy and timeliness.

---

## Summary
The MIT AI Risk Repository addresses the critical challenge of fragmented understanding about AI risks by creating the first comprehensive, publicly accessible database of AI-related risks. Led by Peter Slattery and a team of researchers from MIT FutureTech, the University of Queensland, and other institutions, this project systematically reviewed and catalogued 777 unique risks extracted from 43 existing taxonomies, including peer-reviewed articles, preprints, conference papers, and institutional reports.

The repository features two complementary classification systems. The Causal Taxonomy examines how, when, and why risks occur by analysing three dimensions: the entity involved (human or AI), the intentionality (intentional or unintentional), and the timing of the risk (pre-deployment or post-deployment). The Domain Taxonomy organises risks into seven primary domains: discrimination and toxicity, privacy and security, misinformation, malicious actors and misuse, human-computer interaction, socioeconomic and environmental impacts, and AI system safety, failures, and limitations. These domains are further refined into 23 subdomains for more granular categorisation.

The research reveals significant gaps and imbalances in how AI risks are currently understood and discussed. Whilst more than 70% of existing frameworks address privacy and security concerns, and 76% cover AI system safety issues, only about 40% mention misinformation risks, and some critical areas like AI welfare and rights receive less than 1% coverage. This fragmentation suggests that stakeholders may develop incomplete risk assessments by consulting only a few sources. The repository is designed as a living database, accessible via website and downloadable spreadsheets, that will be regularly updated with new risks, research findings, and emerging trends to serve as a common frame of reference for the global AI community.

---
**Captured:** 25 November 2025

**Link:** https://airisk.mit.edu/

**Key Words:** AI; Risk Management; Taxonomy; Safety; Governance

# Towards Societal Acceptance of Artificial Beings
**Authors:** Daniel I. Thomas, Ljubo B. Vlacic

**Category:** Architecture & Operations

**Published:** 2009

---

## Key Points
- Introduces the concept of Fully Equal Partners (FEPs) where artificial beings collaborate with humans as genuine equals rather than intelligent tools, capable of mutual influence in decision-making processes.
- Demonstrates through empirical testing that artificial agents can effectively participate in collaborative negotiation scenarios, achieving 70% alignment with human outcomes in real-world enterprise project planning.
- Identifies the "collaborative gap" as a measurable difference between human and artificial group decision-making outcomes, establishing a framework for improving AI integration into social processes.
- Proposes a three-layer collaborative architecture (communications, physical, and cognitive) as foundational infrastructure for human-artificial being partnerships across domains from enterprise training to autonomous transportation.
- Emphasises that social acceptance and influence capabilities are prerequisites for artificial beings transitioning from tools to collaborative partners, requiring both technical advancement and cultural adaptation.

---

## Summary
This 2009 paper presents a visionary framework for integrating artificial beings into human organisations as Fully Equal Partners (FEPs) rather than mere intelligent tools. Thomas and Vlacic argue that for artificial entities to become genuine collaborative partners, they must possess social influence capabilities and achieve societal acceptance within groups and organisations. The authors introduce a three-layer collaborative architecture encompassing communications, physical, and cognitive layers to facilitate equal partnership between humans and artificial beings who may be unaware of each other's nature.

The research demonstrates these concepts through a play scenario based on real-world enterprise software project planning, where eleven business units negotiate project priorities within budget constraints. Using artificial FEPs employing fuzzy logic decision-making and various influence mechanisms (arbitrary authority and common interest), the experiments achieved approximately 70% alignment with actual human industry results. This "collaborative gap" represents the measurable difference between human and artificial group outcomes when given identical goals and constraints, providing a metric for advancement toward genuine partnership.

**Remarkably ahead of its time:** Published in 2009—when AI agents were primitive, autonomous vehicles were nascent, and concepts like ChatGPT were science fiction—this paper anticipated many challenges we face in 2026. The authors foresaw applications in business intelligence, autonomous transportation systems, entertainment, and behavioural studies that have since materialised. Their emphasis on societal acceptance, cultural perceptions, and the need to overcome science fiction stereotypes remains directly relevant to current debates about AI integration. The paper's vision of artificial beings as collaborative partners with social influence capabilities, rather than tools, presaged contemporary discussions about AI agents, multi-agent orchestration, and human-AI collaboration that dominate today's AI landscape.

---
**Captured:** 19 January 2026

**Link:** https://www.researchgate.net/profile/Ljubo-Vlacic/publication/267370095_Toward_Societal_Acceptance_of_Artificial_Beings/links/547d17730cf285ad5b088a29/Toward-Societal-Acceptance-of-Artificial-Beings.pdf

**DOI:** 10.4018/978-1-60566-026-4.ch602

**Key Words:** Multi-agent systems; Human-AI collaboration; Social influence; Organisational acceptance; Collaborative decision-making

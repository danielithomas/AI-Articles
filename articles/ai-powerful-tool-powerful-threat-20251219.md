# Artificial Intelligence Is a Powerful Tool â€“ But It Can Also Be a Powerful Threat
**Authors:** Louis Cremen (Lumify Work)

**Category:** Security & Risk

**Published:** 21 November 2025

---

## Key Points
- AI systems can fail fast with large-scale impact, particularly when given access to sensitive corporate data without proper authorisation controls.
- AI-powered phishing attacks lack traditional telltale signs like spelling errors and can be personalised using publicly available information such as LinkedIn profiles.
- Deepfake attacks impersonating executives - particularly CFOs - have resulted in significant financial losses, including over $200 million at Noosa Council in Australia.
- AI-generated malware can adapt to environments in real-time, writing scripts to bypass specific security controls once inside a network.
- AI governance should focus on enabling safe, responsible innovation rather than simply slowing down adoption.

---

## Summary
This article is a transcript from a Cyber Daily podcast interview with Louis Cremen, Lead Cyber Security Instructor at Lumify Work, discussing the dual nature of AI as both a workplace productivity tool and a significant security threat. The conversation explores the rapid improvement in AI capabilities over the past 15-20 years and the corresponding expansion of the attack surface available to malicious actors.

Cremen highlights several concerning trends in AI-enabled attacks. AI systems that lack fine-grained authorisation controls can inadvertently expose sensitive data like HR records or executive salaries to anyone with system access. LLM-powered phishing attacks have become more sophisticated and can now effectively target non-English speaking countries, while deepfake technology has enabled multi-million dollar fraud incidents through convincing executive impersonation. He notes that both state actors and criminal groups are increasingly leveraging AI-enhanced techniques.

The discussion emphasises that effective AI governance is not about slowing innovation but ensuring it happens responsibly. Key risks identified include data poisoning, prompt injection, model theft, unbounded resource consumption leading to unexpected costs, and maintaining the integrity of both inputs and outputs in AI systems. The scope and scale of potential AI attacks has expanded dramatically, requiring organisations to rethink their security posture.

---
**Captured:** 19 December 2025

**Link:** https://www.cyberdaily.au/security/12938-artificial-intelligence-is-a-powerful-tool-but-it-can-also-be-a-powerful-threat

**Key Words:** AI Security; Deepfakes; Phishing; AI Governance; Threat Intelligence
